{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf5ft3y35GRm",
        "outputId": "2c65e981-781f-44d6-dfe8-de7cf38fde4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.5)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.8)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas\n",
        "\n",
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/uldisvalainis/audio-emotions/data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPPslE355DK7",
        "outputId": "b5efc790-30c9-46a5-b930-e00156f36ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: gehansherif\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/uldisvalainis/audio-emotions\n",
            "Downloading audio-emotions.zip to ./audio-emotions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.12G/1.12G [01:06<00:00, 18.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall librosa resampy -y\n",
        "!pip install librosa resampy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yx9Q0F751Se",
        "outputId": "0b16d444-19fc-48b5-96fb-306daf28b5ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: librosa 0.10.2.post1\n",
            "Uninstalling librosa-0.10.2.post1:\n",
            "  Successfully uninstalled librosa-0.10.2.post1\n",
            "\u001b[33mWARNING: Skipping resampy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting librosa\n",
            "  Using cached librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting resampy\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.7.4)\n",
            "Using cached librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: resampy, librosa\n",
            "Successfully installed librosa-0.10.2.post1 resampy-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def extract_features(file_name):\n",
        "    \"\"\"\n",
        "    Extracts MFCC features from an audio file.\n",
        "    \"\"\"\n",
        "    audio, sample_rate = librosa.load(file_name,res_type='kaiser_fast')\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    return mfccs.T\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Loads the dataset, extracts features and labels, and returns them as numpy arrays.\n",
        "    \"\"\"\n",
        "    dataset_path = \"/content/audio-emotions/Emotions\"\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for emotion_dir in os.listdir(dataset_path):\n",
        "        emotion_path = os.path.join(dataset_path, emotion_dir)\n",
        "        if os.path.isdir(emotion_path):\n",
        "            for file_name in os.listdir(emotion_path):\n",
        "                file_path = os.path.join(emotion_path, file_name)\n",
        "                data = extract_features(file_path)\n",
        "                if data is not None:\n",
        "                    features.append(data)\n",
        "                    labels.append(emotion_dir)\n",
        "\n",
        "    # Pad sequences to ensure they are all the same length\n",
        "    max_length = max([len(f) for f in features])\n",
        "    padded_features = np.array([np.pad(f, ((0, max_length - len(f)), (0, 0)), mode='constant') for f in features])\n",
        "\n",
        "    X = np.array(padded_features)\n",
        "    y = np.array(labels)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(y)\n",
        "    y = tf.keras.utils.to_categorical(y, num_classes=len(label_encoder.classes_))\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Load data, extract features, and train the model\n",
        "X, y = load_data()"
      ],
      "metadata": {
        "id": "hqI6i6C-9iJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_model(input_shape, num_classes):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv1D(64, kernel_size=5, strides=1, padding=\"same\", input_shape=input_shape),\n",
        "        tf.keras.layers.Activation(\"relu\"),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=8),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.LSTM(128, return_sequences=True),\n",
        "        tf.keras.layers.LSTM(64),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')  # Adjusted to num_classes\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_model(X_train, y_train, X_val, y_val, num_classes):\n",
        "    model = build_model((X_train.shape[1], X_train.shape[2]), num_classes)\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=30, batch_size=32)\n",
        "    return model, history\n",
        "\n",
        "num_classes = y.shape[1]\n",
        "\n",
        "# First, split the data into training+validation (80%) and test (20%)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now, split the training+validation into training (80% of 80% -> 64%) and validation (20% of 80% -> 16%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check shapes\n",
        "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation set shape: {X_val.shape}, {y_val.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}, {y_test.shape}\")\n",
        "\n",
        "# Train the model with the training and validation sets\n",
        "model, history = train_model(X_train, y_train, X_val, y_val, y_train.shape[1])\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_nvGB4ODuaS",
        "outputId": "e2403284-85bc-496d-8f80-fcb84f91ad54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (8190, 308, 40), (8190, 7)\n",
            "Validation set shape: (2048, 308, 40), (2048, 7)\n",
            "Test set shape: (2560, 308, 40), (2560, 7)\n",
            "Epoch 1/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 121ms/step - accuracy: 0.2392 - loss: 1.7908 - val_accuracy: 0.4146 - val_loss: 1.4829\n",
            "Epoch 2/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 121ms/step - accuracy: 0.4145 - loss: 1.4609 - val_accuracy: 0.4419 - val_loss: 1.3524\n",
            "Epoch 3/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 118ms/step - accuracy: 0.4519 - loss: 1.3529 - val_accuracy: 0.4834 - val_loss: 1.2998\n",
            "Epoch 4/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 114ms/step - accuracy: 0.4858 - loss: 1.2877 - val_accuracy: 0.5190 - val_loss: 1.1881\n",
            "Epoch 5/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 123ms/step - accuracy: 0.5123 - loss: 1.1968 - val_accuracy: 0.4893 - val_loss: 1.2927\n",
            "Epoch 6/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 115ms/step - accuracy: 0.5190 - loss: 1.1923 - val_accuracy: 0.5459 - val_loss: 1.1428\n",
            "Epoch 7/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 115ms/step - accuracy: 0.5277 - loss: 1.1832 - val_accuracy: 0.5552 - val_loss: 1.1231\n",
            "Epoch 8/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 114ms/step - accuracy: 0.5671 - loss: 1.1110 - val_accuracy: 0.5576 - val_loss: 1.1290\n",
            "Epoch 9/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 114ms/step - accuracy: 0.5570 - loss: 1.1023 - val_accuracy: 0.5771 - val_loss: 1.0732\n",
            "Epoch 10/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 115ms/step - accuracy: 0.5693 - loss: 1.0836 - val_accuracy: 0.5918 - val_loss: 1.0497\n",
            "Epoch 11/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 116ms/step - accuracy: 0.5892 - loss: 1.0514 - val_accuracy: 0.5840 - val_loss: 1.0309\n",
            "Epoch 12/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 117ms/step - accuracy: 0.5737 - loss: 1.0507 - val_accuracy: 0.6035 - val_loss: 1.0191\n",
            "Epoch 13/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 116ms/step - accuracy: 0.5850 - loss: 1.0346 - val_accuracy: 0.6099 - val_loss: 1.0031\n",
            "Epoch 14/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 114ms/step - accuracy: 0.5973 - loss: 1.0157 - val_accuracy: 0.6055 - val_loss: 0.9999\n",
            "Epoch 15/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 121ms/step - accuracy: 0.6107 - loss: 0.9944 - val_accuracy: 0.6084 - val_loss: 1.0052\n",
            "Epoch 16/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 115ms/step - accuracy: 0.6104 - loss: 0.9903 - val_accuracy: 0.6055 - val_loss: 0.9868\n",
            "Epoch 17/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 131ms/step - accuracy: 0.6153 - loss: 0.9839 - val_accuracy: 0.6235 - val_loss: 0.9681\n",
            "Epoch 18/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 124ms/step - accuracy: 0.6192 - loss: 0.9699 - val_accuracy: 0.6328 - val_loss: 0.9566\n",
            "Epoch 19/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 114ms/step - accuracy: 0.6204 - loss: 0.9565 - val_accuracy: 0.6177 - val_loss: 0.9690\n",
            "Epoch 20/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 115ms/step - accuracy: 0.6346 - loss: 0.9275 - val_accuracy: 0.6362 - val_loss: 0.9489\n",
            "Epoch 21/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 113ms/step - accuracy: 0.6231 - loss: 0.9550 - val_accuracy: 0.6250 - val_loss: 0.9576\n",
            "Epoch 22/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 122ms/step - accuracy: 0.6310 - loss: 0.9258 - val_accuracy: 0.6387 - val_loss: 0.9194\n",
            "Epoch 23/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 114ms/step - accuracy: 0.6469 - loss: 0.9034 - val_accuracy: 0.6401 - val_loss: 0.9196\n",
            "Epoch 24/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 112ms/step - accuracy: 0.6394 - loss: 0.9170 - val_accuracy: 0.6372 - val_loss: 0.9214\n",
            "Epoch 25/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 120ms/step - accuracy: 0.6408 - loss: 0.9035 - val_accuracy: 0.6396 - val_loss: 0.9259\n",
            "Epoch 26/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 118ms/step - accuracy: 0.6465 - loss: 0.8902 - val_accuracy: 0.6523 - val_loss: 0.8992\n",
            "Epoch 27/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 113ms/step - accuracy: 0.6482 - loss: 0.8972 - val_accuracy: 0.6455 - val_loss: 0.9085\n",
            "Epoch 28/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 124ms/step - accuracy: 0.6503 - loss: 0.8814 - val_accuracy: 0.6396 - val_loss: 0.9355\n",
            "Epoch 29/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 115ms/step - accuracy: 0.6527 - loss: 0.8906 - val_accuracy: 0.6538 - val_loss: 0.8756\n",
            "Epoch 30/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 114ms/step - accuracy: 0.6542 - loss: 0.8813 - val_accuracy: 0.6348 - val_loss: 0.9249\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.6143 - loss: 0.9591\n",
            "Test accuracy: 0.617968738079071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, MaxPooling1D, Input, Attention, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_enhanced_model(input_shape, num_classes):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # Convolutional layers\n",
        "    x = Conv1D(64, kernel_size=5, strides=1, padding=\"same\", activation='relu')(input_layer)\n",
        "    x = MaxPooling1D(pool_size=8)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # LSTM layers with Bidirectional and Attention\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "    x = Attention()([x, x])\n",
        "    x = Bidirectional(LSTM(64))(x)\n",
        "\n",
        "    # Output layer\n",
        "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(X_train, y_train, X_val, y_val, num_classes):\n",
        "    model = build_enhanced_model((X_train.shape[1], X_train.shape[2]), num_classes)\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=30, batch_size=32)\n",
        "    return model, history\n",
        "\n",
        "# Train the model with the training and validation sets\n",
        "model, history = train_model(X_train, y_train, X_val, y_val, y_train.shape[1])\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ2X1VDdOGQM",
        "outputId": "10bdd54a-a7e2-498c-fab4-ca4ef95c5212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (8190, 308, 40), (8190, 7)\n",
            "Validation set shape: (2048, 308, 40), (2048, 7)\n",
            "Test set shape: (2560, 308, 40), (2560, 7)\n",
            "Epoch 1/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 219ms/step - accuracy: 0.2638 - loss: 1.7602 - val_accuracy: 0.4536 - val_loss: 1.3656\n",
            "Epoch 2/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 225ms/step - accuracy: 0.4546 - loss: 1.3612 - val_accuracy: 0.5200 - val_loss: 1.1861\n",
            "Epoch 3/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 225ms/step - accuracy: 0.5289 - loss: 1.1741 - val_accuracy: 0.5635 - val_loss: 1.0862\n",
            "Epoch 4/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 215ms/step - accuracy: 0.5655 - loss: 1.0992 - val_accuracy: 0.5503 - val_loss: 1.1140\n",
            "Epoch 5/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 224ms/step - accuracy: 0.5892 - loss: 1.0554 - val_accuracy: 0.6011 - val_loss: 0.9828\n",
            "Epoch 6/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 214ms/step - accuracy: 0.5978 - loss: 1.0009 - val_accuracy: 0.6270 - val_loss: 0.9673\n",
            "Epoch 7/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 228ms/step - accuracy: 0.6222 - loss: 0.9631 - val_accuracy: 0.6216 - val_loss: 0.9550\n",
            "Epoch 8/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 216ms/step - accuracy: 0.6346 - loss: 0.9250 - val_accuracy: 0.6460 - val_loss: 0.9090\n",
            "Epoch 9/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 216ms/step - accuracy: 0.6441 - loss: 0.9121 - val_accuracy: 0.6533 - val_loss: 0.9100\n",
            "Epoch 10/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 220ms/step - accuracy: 0.6511 - loss: 0.9009 - val_accuracy: 0.6860 - val_loss: 0.8585\n",
            "Epoch 11/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 219ms/step - accuracy: 0.6587 - loss: 0.8639 - val_accuracy: 0.6621 - val_loss: 0.8708\n",
            "Epoch 12/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 217ms/step - accuracy: 0.6649 - loss: 0.8537 - val_accuracy: 0.6582 - val_loss: 0.8849\n",
            "Epoch 13/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 216ms/step - accuracy: 0.6768 - loss: 0.8268 - val_accuracy: 0.6636 - val_loss: 0.8606\n",
            "Epoch 14/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 216ms/step - accuracy: 0.6848 - loss: 0.8212 - val_accuracy: 0.6733 - val_loss: 0.8366\n",
            "Epoch 15/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 221ms/step - accuracy: 0.6829 - loss: 0.8000 - val_accuracy: 0.6982 - val_loss: 0.8124\n",
            "Epoch 16/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 214ms/step - accuracy: 0.7019 - loss: 0.7777 - val_accuracy: 0.6904 - val_loss: 0.8154\n",
            "Epoch 17/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 237ms/step - accuracy: 0.7031 - loss: 0.7704 - val_accuracy: 0.6924 - val_loss: 0.8161\n",
            "Epoch 18/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 214ms/step - accuracy: 0.6926 - loss: 0.7889 - val_accuracy: 0.6670 - val_loss: 0.8502\n",
            "Epoch 19/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 215ms/step - accuracy: 0.7059 - loss: 0.7425 - val_accuracy: 0.6943 - val_loss: 0.7926\n",
            "Epoch 20/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 216ms/step - accuracy: 0.7154 - loss: 0.7589 - val_accuracy: 0.6973 - val_loss: 0.7856\n",
            "Epoch 21/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 216ms/step - accuracy: 0.7166 - loss: 0.7285 - val_accuracy: 0.7178 - val_loss: 0.7737\n",
            "Epoch 22/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 223ms/step - accuracy: 0.7106 - loss: 0.7369 - val_accuracy: 0.6836 - val_loss: 0.8045\n",
            "Epoch 23/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 216ms/step - accuracy: 0.7230 - loss: 0.7250 - val_accuracy: 0.7144 - val_loss: 0.7637\n",
            "Epoch 24/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 225ms/step - accuracy: 0.7138 - loss: 0.7252 - val_accuracy: 0.7134 - val_loss: 0.7519\n",
            "Epoch 25/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 217ms/step - accuracy: 0.7277 - loss: 0.6980 - val_accuracy: 0.7007 - val_loss: 0.7839\n",
            "Epoch 26/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 231ms/step - accuracy: 0.7382 - loss: 0.6852 - val_accuracy: 0.7061 - val_loss: 0.7945\n",
            "Epoch 27/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 220ms/step - accuracy: 0.7323 - loss: 0.6936 - val_accuracy: 0.7090 - val_loss: 0.7600\n",
            "Epoch 28/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 223ms/step - accuracy: 0.7366 - loss: 0.6780 - val_accuracy: 0.7051 - val_loss: 0.7917\n",
            "Epoch 29/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 216ms/step - accuracy: 0.7369 - loss: 0.6687 - val_accuracy: 0.7124 - val_loss: 0.8007\n",
            "Epoch 30/30\n",
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 224ms/step - accuracy: 0.7461 - loss: 0.6665 - val_accuracy: 0.6987 - val_loss: 0.8172\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.6804 - loss: 0.8744\n",
            "Test accuracy: 0.682421863079071\n"
          ]
        }
      ]
    }
  ]
}